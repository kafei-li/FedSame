# FedSame: A Bayesian Similarity-Aware Framework for Federated Multi-Task Learning

This repository contains the official implementation of the paper **"FedSame: A Bayesian Similarity-Aware Framework for Federated Multi-Task Learning"**.

FedSame dynamically models the relationships between tasks in a federated learning setting using Bayesian inference, which allows for more accurate and adaptive multi-task collaboration, especially under non-IID data distributions.

## ðŸ“– Paper Abstract
Accurate dynamic modeling of task correlations is crucial for enhancing collaborative efficiency and personalized performance in federated multi-task learning, yet existing approaches struggle with heterogeneous environments due to static assumptions or implicit modeling. Moreover, task relationships typically remain implicit, embedded within data distributions and parameter variations, making precise modeling inherently challenging. This challenge is further intensified in Non-IID settings, where data heterogeneity impedes both the identification and accurate estimation of task relationships. To address these challenges, we propose FedSame, a similarity-aware federated multi-task learning framework that leverages Bayesian inference to dynamically model inter-task relationships. The key innovation of FedSame lies in its probabilistic reformulation of task relationship modeling, where an adaptive similarity matrix undergoes continuous Bayesian updates to precisely track evolving task relationships. FedSame's technical core combines Beta distribution priors with Bayesian update rules, enabling fine-grained detection of subtle variations in task relationship variations during training, and computationally efficient dynamic updates by leveraging the conjugacy property of Beta distribution. Extensive experiments on three real datasets and a synthetic dataset demonstrate that FedSame consistently outperforms five state-of-the-art baselines in both task relationship modeling accuracy and multi-task classification performance. Notably, FedSame achieves 85% multi-attribute classification accuracy on CelebA and 83% accuracy in task relationship modeling on synthetic data while demonstrating strong robustness and adaptability in heterogeneous, real-world federated settings. 

## ðŸš€ Features
- **Bayesian Dynamic Similarity Modeling**: Uses Beta distribution priors and Bayesian updates to explicitly and dynamically model inter-task relationships.
- **Multiple Baseline Implementations**: Includes implementations of FedBone, MTPL, MOCHA, MAS, and FedEM for comprehensive comparison.
- **Extensive Dataset Support**: Code supports MNIST, CelebA, a Synthetic dataset, and an Ophthalmic dataset.
- **Configurable Heterogeneity**: Easily simulate different levels of data heterogeneity among clients using Dirichlet distribution.

## Dependencies

```bash
pip install -r requirements.txt
```

Dataset Preparation

- MNIST: Will be automatically downloaded to `data/mnist/` by the torchvision dataloader on first run.
- CelebA: Download Link  (http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html)ï¼Œplaced in `data/celeba/`
- Synthetic: Automatically generated by the code

## Configuration:
Hyperparameters are controlled in the Config class within config.py. Key parameters include:

num_rounds: Total number of communication rounds.
clients_per_round: Fraction of clients selected each round.
local_epochs: Number of local training epochs on each client.
learning_rate: Learning rate for local SGD.
alpha, beta: Parameters for the Beta prior in FedSame.
m: Observation impact factor for Bayesian updates in FedSame.
dirichlet_alpha: Parameter controlling data heterogeneity (Non-IIDness). A smaller value means higher heterogeneity.

## Hyperparameter Settings

- Beta prior: alpha=2, beta=2
- Observation impact: m=10
- Learning rate: 0.01
- Regularization: lambda=0.1
- Dirichlet alpha: 0.1 or 0.01 (Non-IID)

## Running Experiments
The main entry point is main.py. You can run experiments using the following command:
python main.py --dataset <dataset_name> --method <method_name>

## Project Structure
â”œâ”€â”€ main.py                 # Main script to launch experiments
â”œâ”€â”€ config.py              # Configuration class for hyperparameters
â”œâ”€â”€ data_utils.py          # Data loading and partitioning functions
â”œâ”€â”€ fedsame.py             # Core implementation of the FedSame algorithm
â”œâ”€â”€ baselines.py           # Implementations of all baseline methods
â”œâ”€â”€ models.py              # Model architectures for different datasets
â”œâ”€â”€ utils.py               # Utility functions (evaluation, Gini coefficient)
â”œâ”€â”€ requirements.txt       # Python dependencies
â””â”€â”€ README.md              # This file

